{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMILES_featurization_try_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lBB-oQjDa9xwvLgRahZeBKzyx6AgJzSU",
      "authorship_tag": "ABX9TyM5MBSC+fG8NmPxwhQG2oY2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veren4/Kinase_residue_classification/blob/master/SMILES_featurization_try_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtOzr6JeTTZy",
        "colab_type": "text"
      },
      "source": [
        "This notebook is based on an official AllenNLP example: https://allennlp.org/tutorials \\\n",
        "And on this [second, more detailed tutorial](https://mlexplained.com/2019/01/30/an-in-depth-tutorial-to-allennlp-from-basics-to-elmo-and-bert/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktbo1UgggHDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install allennlp==0.9\n",
        "!pip install SmilesPE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsQNCG_UFQ9e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e888575c-1fae-4bb4-b2b7-435d8c2f3003"
      },
      "source": [
        "#import allennlp\n",
        "#print(allennlp.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Cer_5OTfrG",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp76-i0UN_Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Iterator, List, Dict         # type annotations\n",
        "\n",
        "import torch                                    # AllenNLP is built on PyTorch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from allennlp.data import Instance              # training sample = Instance containing fields"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6OGeoVQPx4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.fields import TextField, SequenceLabelField      # possible fields: http://docs.allennlp.org/v0.9.0/api/allennlp.data.fields.html"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H02BqLbCS47v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.dataset_readers import DatasetReader     # reads a file and produces a stream of Instances"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeRDje-ATMxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer     # Tokenindexer: rule for how to turn a token into indices\n",
        "from allennlp.data.tokenizers import Token\n",
        "\n",
        "# The Tokenizer I used before:\n",
        "from SmilesPE.pretokenizer import atomwise_tokenizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDc3OIifV3os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.vocabulary import Vocabulary     # mapping from strings -> integers\n",
        "\n",
        "from allennlp.models import Model                   # a PyTorch Module\n",
        "                                                    # input: tensors\n",
        "                                                    # output: dict of tensor output (including the training loss)\n",
        "\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
        "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
        "\n",
        "from allennlp.training.metrics import CategoricalAccuracy       # for tracking accuracy on the training and validation datasets\n",
        "                                                                # accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
        "\n",
        "from allennlp.data.iterators import BasicIterator\n",
        "\n",
        "from allennlp.training.trainer import Trainer\n",
        "\n",
        "from allennlp.predictors import SentenceTaggerPredictor # make predictions on new input"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST8fKTFNg3Ik",
        "colab_type": "text"
      },
      "source": [
        "Iterator: Batches the data \\\n",
        "Trainer: Handles training and metric recording \\\n",
        "(Predictor: Generates predictions from raw strings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0_avpxb3rgf",
        "colab_type": "text"
      },
      "source": [
        "Things to consider for the Iterator:\n",
        "* Sequences of different lengths need to be padded\n",
        "* To minimize padding, sequences of similar lengths can be put in the same batch\n",
        "* Tensors need to be sent to the GPU if using the GPU\n",
        "* Data needs to be shuffled at the end of each epoch during training, but we don't want to shuffle in the midst of an epoch in order to cover all examples evenly\n",
        "\n",
        "\n",
        "The BucketIterator batches sequences of similar lengths together to minimize padding. -> But I set a global max size, right?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwEAwihsTlcA",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tatEr9psU5H5",
        "colab_type": "text"
      },
      "source": [
        "Achtung: Ich muss bei dem PubChem sample file die Zeilennummerierung wegschneiden!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGvR0qlOV1Kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce103a68-b0d8-4d65-8133-2f66d806ab6a"
      },
      "source": [
        "torch.manual_seed(1)   # Set random seed manually to replicate results"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f26a700ed38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNZew5hagjD6",
        "colab_type": "text"
      },
      "source": [
        "DatasetReader: Extracts necessary information from data into a list of Instance objects \\\n",
        "1. Reading the data from disk\n",
        "2. Extracting relevant information from the data\n",
        "3. Converting the data into a list of Instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYAx0FD-YjEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SMILES_tokens_DatasetReader(DatasetReader):\n",
        "\n",
        "    def __init__(self, token_indexers: Dict[str, TokenIndexer] = None):\n",
        "        super().__init__(lazy=False)\n",
        "        self.tokenizer = atomwise_tokenizer()   # PROBABLY WRONG\n",
        "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}      # unique ID for each distinct token\n",
        "#       self.max_seq_len = max_seq_len          # Add max value!\n",
        "\n",
        "    @overrides\n",
        "    def text_to_instance(self,                                    # goal:  take the data for a single example and pack it into an Instance object\n",
        "                         tokens: List[Token],\n",
        "                         tags: List[str] = None) -> Instance:\n",
        "        # I want to take 1 line (without maybe EOL characters!)\n",
        "\n",
        "        # I could write my own Field class..\n",
        "        SMILES_field = TextField(tokens, self.token_indexers)     # Before constructing this object,\n",
        "                                                                  # I need to tokenize the raw strings using a Tokenizer\n",
        "        fields = {\"sentence\": SMILES_field}\n",
        "\n",
        "        if tags:\n",
        "            label_field = SequenceLabelField(labels=tags, sequence_field=sentence_field)\n",
        "            fields[\"labels\"] = label_field\n",
        "\n",
        "        return Instance(fields)\n",
        "\n",
        "    @overrides\n",
        "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
        "        with open(downloads) as f:        # file: downloads (see above)\n",
        "            for line in f:\n",
        "                pairs = line.strip().split()\n",
        "                sentence, tags = zip(*(pair.split(\"###\") for pair in pairs))\n",
        "                yield self.text_to_instance([Token(word) for word in sentence], tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIA2JfVPguVX",
        "colab_type": "text"
      },
      "source": [
        "AllenNLP models are generally composed from the following components:\n",
        "* A token embedder\n",
        "* An encoder\n",
        "* (For seq-to-seq models) A decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grn9pfQhYqa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "ffb7c2e7-5a70-4877-848f-d1d3b1e4aeb7"
      },
      "source": [
        "class LstmTagger(Model):                # subclass of the torch.nn.Module\n",
        "\n",
        "    def __init__(self,\n",
        "                 word_embeddings: TextFieldEmbedder,\n",
        "                 encoder: Seq2SeqEncoder,\n",
        "                 vocab: Vocabulary) -> None:\n",
        "\n",
        "        super().__init__(vocab)\n",
        "        self.word_embeddings = word_embeddings\n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.hidden2tag = torch.nn.Linear(in_features=encoder.get_output_dim(),\n",
        "                                          out_features=vocab.get_vocab_size('labels'))\n",
        "\n",
        "        #self.accuracy = CategoricalAccuracy()\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                sentence: Dict[str, torch.Tensor],\n",
        "                labels: torch.Tensor = None) -> Dict[str, torch.Tensor]:\n",
        "        mask = get_text_field_mask(tokens)\n",
        "\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "\n",
        "        encoder_out = self.encoder(embeddings, mask)    # state\n",
        "\n",
        "        class_logits = self.hidden2tag(encoder_out)    # oder: self.projection(encoder_out)\n",
        "\n",
        "        output = {\"class_logits\": class_logits}\n",
        "\n",
        "        # The loss must be computed within the forward method during training.\n",
        "\n",
        "        if labels is not None:\n",
        "            #self.accuracy(tag_logits, labels, mask)\n",
        "            output[\"loss\"] = sequence_cross_entropy_with_logits(tag_logits, labels, mask)\n",
        "\n",
        "        return output\n",
        "\n",
        "    #def backward(self)\n",
        "\n",
        "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
        "        return {\"accuracy\": self.accuracy.get_metric(reset)}\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-1df7653b7517>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    def backward(self)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZQxEWe-p4VF",
        "colab_type": "text"
      },
      "source": [
        "**Embedder**\\\n",
        "sequence of token IDs -> sequence of tensors\\\n",
        "I need 2 classes for handling embeddings: Embedding class + BasicTextFieldEmbedder class\\\n",
        "\\\n",
        "**Encoder**\\\n",
        "sequence of embeddings -> 1 vector\n",
        "model in AllenNLP: Seq2VecEncoder (there are several variations available)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VieaweZHZ7j7",
        "colab_type": "text"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lakQkm8TFNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data as a cached_path??\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '1lX3mV3DBYiMxp4xICvUt4fxRyeNSpwN7'\n",
        "downloaded = drive.CreateFile({'id': file_id})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVybX5b4e7L9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(downloaded.GetContentString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBCI9J1kToBt",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjSDq9N7Y7rb",
        "colab_type": "text"
      },
      "source": [
        "Split the dataset into train, validate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38O2NYCNz8jE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_data = []\n",
        "\n",
        "for line in downloaded.GetContentString().splitlines():\n",
        "  my_data.append(line)\n",
        "\n",
        "my_data = list(filter(None, my_data))               # 1 list item = 1 SMILES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsOzwrjA1pRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset, val_dataset = train_test_split(my_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szyRaYc42LRf",
        "colab_type": "text"
      },
      "source": [
        "Tokenize the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psHmbZ2n2OTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#toks = atomwise_tokenizer(smi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSiXQNvxTpmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reader = SMILES_tokens_DatasetReader()                     # create an instance of the DatasetReader\n",
        "\n",
        "vocab = Vocabulary.from_instances(train_dataset + validation_dataset)\n",
        "\n",
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6\n",
        "\n",
        "# The embedder maps a sequence of token ids (or character ids) into a sequence of tensors. Here: simple\n",
        "# embedding matrix:\n",
        "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
        "                            embedding_dim=EMBEDDING_DIM)            # character encoding\n",
        "                            \n",
        "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})   # word encoding\n",
        "\n",
        "# To classify each sentence, we need to convert the sequence of embeddings into\n",
        "# a single vector. In AllenNLP, the model that handles this is referred to as a\n",
        "# Seq2VecEncoder: a mapping from sequences to a single vector.\n",
        "lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
        "\n",
        "model = LstmTagger(word_embeddings, lstm, vocab)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    cuda_device = 0\n",
        "\n",
        "    model = model.cuda(cuda_device)\n",
        "else:\n",
        "\n",
        "    cuda_device = -1\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "iterator = BucketIterator(batch_size=2, sorting_keys=[(\"sentence\", \"num_tokens\")])\n",
        "\n",
        "iterator.index_with(vocab)\n",
        "\n",
        "trainer = Trainer(model=model,              # instantiate the trainer\n",
        "                  optimizer=optimizer,\n",
        "                  iterator=iterator,\n",
        "                  train_dataset=train_dataset,\n",
        "                  validation_dataset=validation_dataset,\n",
        "                  patience=10,\n",
        "                  num_epochs=1000,\n",
        "                  cuda_device=cuda_device)\n",
        "\n",
        "trainer.train()                             # run the trainer\n",
        "\n",
        "predictor = SentenceTaggerPredictor(model, dataset_reader=reader)\n",
        "\n",
        "tag_logits = predictor.predict(\"The dog ate the apple\")['tag_logits']\n",
        "\n",
        "tag_ids = np.argmax(tag_logits, axis=-1)\n",
        "\n",
        "print([model.vocab.get_token_from_index(i, 'labels') for i in tag_ids])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGF-m8NFYwEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor2 = SentenceTaggerPredictor(model2, dataset_reader=reader)\n",
        "tag_logits2 = predictor2.predict(\"The dog ate the apple\")['tag_logits']\n",
        "np.testing.assert_array_almost_equal(tag_logits2, tag_logits)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}